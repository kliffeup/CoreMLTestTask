Ноутбук доступен [здесь](https://github.com/kliffeup/CoreMLTestTask/blob/main/Core%20ML%20Test%20Task%2C%20VK%20Internship.ipynb).

# Выбранная метрика

В качестве метрики было решено использовать `MAP@K` - Mean Average Precision @ K, поскольку эта метрика смотрит на ранги предлагаемой выдачи,
что важно для оценки рекомендаций: даём больше *очков* модели за правильные рекомендации именно в самом верху; штраф за неправильные рекомендации в самом топе 
соответственно больше. Это приемущество данной метрики над прочими, которые относятся к выдаче как к множеству рекомендаций, без их упорядочивания.

В части с коллаборативной фильтрацией пришлось реализовывать её самостоятельно - из-за специфики выдаваемых значений рекомендаций моделями из модуля `surprise`.

# Разбиение данных на обучение и тест

Первоначально была взята подвыборка `data` из рекомендаций первых (по `id`) 1000 пользователей, для ускорения экспериментов с моделями.

Затем `data` была поделена на обучение и тест следующим образом:

* выбрали 1000 случайных сэмплов из неё, по одному на каждого из рассматриваемых юзеров, отложили их в `train`, удалив из `data`;
* затем для каждого попавшего в `data`, но не попавшего в `train` фильма взяли по одному случайному сэмплу, закинули в `train`, также убрав из `data`;
* остаток `data` случайно поделили на две части: одну закинули в `train`, вторую назвали `test`, таким образом, чтобы в `train`е оказалось 80% исходной подвыборки `data`;

Такое разбиение данных гарантирует нам, что любая наша модель пощупает все данные ей при обучении "данные" и узнает хоть что-то про всех рассматриваемых пользователей/фильмов. Такое бывает важно, например, для моделей коллаборативной фильтрации, для которых актуальна проблема *холодного старта*.

# Эксперименты

В рамках подхода коллаборативной фильтрации были рассмотрены следующие модели:

* ## SVD

Разложение матрицы *пользователи-фильмы* с их оценками в произведение матриц латентных признаков пользователей и фильмов.

Подбираемые параметры - размерность пространства латентных признаков. Подбор осуществлялся с помощью `GridSearchCV`.

Модель показала самый высокий результат среди тестируемых моделей коллаборативной фильтрации.

* ## User-based KNN

Поиск ближайших соседей для каждого пользователя в матрице *пользователи-фильмы* и оценивание рейтинга фильма для каждого пользователя по взвешенной сумме рейтингов соседей (чем ближе сосед, тем больше вклад).

Подбираемые параметры - `k`, количество ближайших соседей для оценивания; мера близости - msd, косинусная близость, корреляция Пирсона. Подбор осуществлялся с помощью `GridSearchCV`.

Модель показала худший результат среди тестируемых моделей.

* ## Item-based KNN

Поиск ближайших соседей в матрице *пользователи-фильмы* для каждого фильма и оценивание рейтинга фильма по взвешенной сумме рейтингов его соседей (чем ближе сосед, тем больше вклад).

Подбираемые параметры - `k`, количество ближайших соседей для оценивания; мера близости - msd, косинусная близость, корреляция Пирсона. Подбор осуществлялся с помощью `GridSearchCV`.

Модель показала результат, лучший `User-Based KNN`, но незначительно. В целом, обе модели показали себя хуже матричной факторизации `SVD`.

В рамках гибридного подхода была рассмотрена модель LightFM:

* ## LightFM

Матричная факторизация матрицы *пользователи-фильмы* с рейтингами с использование дополнительной информации о фильмах/пользователях для компенсирования проблемы *холодного старта* моделей коллаборативной фильтрации. Модель взята из пакета `lightfm`.

В качестве дополнительной информации использовались жанры фильмов из `movie.csv`.

Подбираемые параметры:

* размерность пространства латентных признаков;
* метод оптимизации: adagrad, adadelta;
* loss-function: 'bpr', 'warp', 'warp-kos';
* learning rate для алгоритма оптимизации;
* коэффициенты регуляризации для признаков фильмов/пользователей;
* максимальное число негативных сэмплов для loss-a *warp*;
* число эпох для обучения.

Подбор осуществлялся с помощью самописного `RandomSearch`, для всех используемых параметров ввелись распределения для сэмплов.

Модель показала лучший результат среди тестируемых моделей, что неудивительно с учётом дополнительной используемой информации, в отличии от моделей коллаборативной фильтрации.
