# Выбранная метрика

В качестве метрики было решено использовать `MAP@K` - Mean Average Precision @ K, поскольку эта метрика смотрит на ранги предлагаемой выдачи,
что важно для оценки рекомендаций: даём больше *очков* модели за правильные рекомендации именно в самом верху; штраф за неправильные рекомендации в самом топе 
соответственно больше. Это приемущество данной метрики над прочими, которые относятся к выдаче как к множеству рекомендаций, без их упорядочивания.

В части с коллаборативной фильтрацией пришлось реализовывать её самостоятельно - из-за специфики выдаваемых значений рекомендаций моделями из модуля `surprise`.

# Разбиение данных на обучение и тест

